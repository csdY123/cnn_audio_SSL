# dataset_sim.py
import torch
from torch.utils.data import Dataset
import numpy as np
import pyroomacoustics as pra
import librosa
import os
import glob
import random

class DynamicRoomSimulator(Dataset):
    def __init__(self, audio_source_dir, sample_length=2048, epoch_length=2000):
        self.sample_length = sample_length
        self.epoch_length = epoch_length
        self.fs = 16000
        
        # -------------------------------------------------------------
        # 1. åŠ è½½éŸ³é¢‘æ–‡ä»¶ (æ”¯æŒ .wav å’Œ .flac)
        # -------------------------------------------------------------
        self.source_files = []
        for ext in ['*.wav', '*.flac']:
            # ä½¿ç”¨ case-insensitive çš„æ–¹å¼æŸ¥æ‰¾æ›´ç¨³å¥ï¼Œä½†åœ¨ Linux ä¸‹é€šå¸¸é€šè¿‡æ‰©å±•åæ§åˆ¶å³å¯
            self.source_files.extend(glob.glob(os.path.join(audio_source_dir, f"**/{ext}"), recursive=True))
            
        if len(self.source_files) == 0:
            raise ValueError(f"åœ¨ {audio_source_dir} æ²¡æ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ (.wav/.flac)!")
        
        print(f"åŠ¨æ€ä»¿çœŸå™¨å·²åŠ è½½: å‘ç° {len(self.source_files)} ä¸ªæºéŸ³é¢‘æ–‡ä»¶")

        # Unitree Go2 éº¦å…‹é£é˜µåˆ—å®šä¹‰ (4ä¸ªéº¦å…‹é£, 3Dåæ ‡)
        self.mic_positions_local = np.array([
            [ 0.1035,  0.0235, 0.0], # mic0
            [ 0.1035, -0.0235, 0.0], # mic1
            [-0.1035, -0.0235, 0.0], # mic2
            [-0.1035,  0.0235, 0.0], # mic3
        ]).T # è½¬ç½®ä¸º 3x4

    def __len__(self):
        return self.epoch_length

    def _get_random_room_params(self):
        """éšæœºç”Ÿæˆæˆ¿é—´å‚æ•°"""
        room_dim = np.array([
            np.random.uniform(3.0, 8.0), np.random.uniform(3.0, 8.0), np.random.uniform(2.5, 3.5)
        ])
        rt60 = np.random.uniform(0.15, 0.6)
        try:
            e_absorption, max_order = pra.inverse_sabine(rt60, room_dim)
            max_order = min(max_order, 5) 
        except:
            e_absorption, max_order = 0.3, 3
        return room_dim, e_absorption, max_order

    def _load_random_source_clip(self, duration_sec=1.0):
        wav_path = random.choice(self.source_files)
        # è·å–æ—¶é•¿ (librosaè¯»å–æœ‰ç‚¹æ…¢ï¼Œä¸ºäº†æ•ˆç‡ï¼Œå®é™…å·¥ç¨‹ä¸­å¯ä»¥ç¼“å­˜æ—¶é•¿ï¼Œä½†è¿™é‡Œå…ˆè¿™æ ·ç”¨)
        full_duration = librosa.get_duration(path=wav_path)
        
        if full_duration <= duration_sec:
            offset = 0.0
        else:
            offset = np.random.uniform(0, full_duration - duration_sec)
        
        y, sr = librosa.load(wav_path, sr=self.fs, offset=offset, duration=duration_sec)
        
        # ç®€å•çš„æºä¿¡å·å½’ä¸€åŒ–ï¼Œé˜²æ­¢æºä¿¡å·å¤ªå°æˆ–å¤ªå¤§
        max_val = np.max(np.abs(y))
        if max_val > 0:
            y = y / max_val
        return y

    def __getitem__(self, idx):
        # -----------------------------------------------------------
        # 1. å‡†å¤‡ç¯å¢ƒ (éšæœºæˆ¿é—´å‚æ•°)
        # -----------------------------------------------------------
        room_dim, e_absorption, max_order = self._get_random_room_params()
        
        # åˆ›å»ºæˆ¿é—´
        room = pra.ShoeBox(
            room_dim, 
            fs=self.fs, 
            materials=pra.Material(e_absorption), 
            max_order=max_order
        )

        # -----------------------------------------------------------
        # 2. æ”¾ç½®éº¦å…‹é£ (éšæœºä½ç½®)
        # -----------------------------------------------------------
        # ä¿è¯é˜µåˆ—ç¦»å¢™è‡³å°‘ 0.5ç±³
        mic_center = np.array([
            np.random.uniform(0.5, room_dim[0] - 0.5),
            np.random.uniform(0.5, room_dim[1] - 0.5),
            np.random.uniform(0.5, room_dim[2] - 0.5) 
        ])
        
        current_mic_locs = self.mic_positions_local + mic_center.reshape(3, 1)
        room.add_microphone_array(current_mic_locs)

        # -----------------------------------------------------------
        # 3. æ”¾ç½®å£°æº (éšæœºè§’åº¦ + æ‰©å¤§è·ç¦» + é«˜åº¦æ‰°åŠ¨)
        # -----------------------------------------------------------
        angle_deg = np.random.randint(0, 360)
        angle_rad = np.deg2rad(angle_deg)
        
        # ğŸ”¥ã€æ”¹è¿›1ã€‘æ‰©å¤§è·ç¦»èŒƒå›´ï¼š0.5m (è¿‘åœº) åˆ° 5.0m (è¿œåœº)
        dist = np.random.uniform(0.5, 5.0)
        
        src_x = mic_center[0] + dist * np.cos(angle_rad)
        src_y = mic_center[1] + dist * np.sin(angle_rad)
        
        # ğŸ”¥ã€å®‰å…¨è¡¥ä¸ Aã€‘é«˜åº¦éšæœºæ‰°åŠ¨ (Z-axis Jitter)
        src_z = mic_center[2] + np.random.uniform(-0.2, 1.5)
        
        # é˜²æ­¢å‡ºç•Œ (Clip X, Y, Z)
        src_x = np.clip(src_x, 0.1, room_dim[0]-0.1)
        src_y = np.clip(src_y, 0.1, room_dim[1]-0.1)
        src_z = np.clip(src_z, 0.1, room_dim[2]-0.1)
        
        # é‡æ–°è®¡ç®—ç”±äºClipå¯¼è‡´çš„çœŸå®è§’åº¦ (Azimuth)
        real_dx = src_x - mic_center[0]
        real_dy = src_y - mic_center[1]
        real_angle_rad = np.arctan2(real_dy, real_dx)
        if real_angle_rad < 0: real_angle_rad += 2*np.pi
        
        # æœ€ç»ˆ Label (0-359)
        label_deg = int(np.degrees(real_angle_rad))
        
        # è¯»å–éšæœºç‰‡æ®µ (0.5ç§’)
        source_signal = self._load_random_source_clip(duration_sec=0.5)
        room.add_source([src_x, src_y, src_z], signal=source_signal)

        # -----------------------------------------------------------
        # 4. è¿è¡Œç‰©ç†ä»¿çœŸ
        # -----------------------------------------------------------
        room.simulate()
        simulated_audio = room.mic_array.signals # Shape: (4, N)

        # -----------------------------------------------------------
        # ğŸ”¥ã€æ”¹è¿›2ã€‘åœ¨çº¿æ³¨å…¥å™ªå£° (Noise Injection)
        # -----------------------------------------------------------
        # éšæœºä¿¡å™ªæ¯” (SNR): 5dB (åµé—¹) - 30dB (å®‰é™)
        target_snr_db = np.random.uniform(5.0, 30.0)
        
        # è®¡ç®—ä¿¡å·èƒ½é‡
        sig_power = np.mean(simulated_audio ** 2)
        if sig_power > 0:
            # æ ¹æ® SNR è®¡ç®—å™ªå£°èƒ½é‡
            noise_power = sig_power / (10 ** (target_snr_db / 10))
            # ç”Ÿæˆé«˜æ–¯ç™½å™ªå£°
            noise = np.random.normal(0, np.sqrt(noise_power), simulated_audio.shape)
            # å åŠ 
            simulated_audio = simulated_audio + noise

        # -----------------------------------------------------------
        # 5. åå¤„ç†ä¸éšæœºè£å‰ª (å«é™éŸ³é˜²å¾¡)
        # -----------------------------------------------------------
        # å½’ä¸€åŒ– (ä¿ç•™ ILD, é¿å…é™¤é›¶)
        max_amp = np.max(np.abs(simulated_audio))
        if max_amp > 0:
            simulated_audio = simulated_audio / max_amp * 0.9
        
        signal_len = simulated_audio.shape[1]
        
        if signal_len > self.sample_length:
            max_start = signal_len - self.sample_length
            
            # ğŸ”¥ã€å®‰å…¨è¡¥ä¸ Bã€‘é™éŸ³åˆ‡ç‰‡é˜²å¾¡ (Silent Crop Protection)
            # å°è¯• 3 æ¬¡éšæœºåˆ‡ç‰‡ï¼Œç¡®ä¿åˆ‡åˆ°çš„ç‰‡æ®µæœ‰è¶³å¤Ÿçš„èƒ½é‡
            for _ in range(3):
                start = np.random.randint(0, max_start + 1)
                cropped = simulated_audio[:, start : start + self.sample_length]
                
                # èƒ½é‡é˜ˆå€¼æ£€æµ‹ (1e-5 æ˜¯ç»éªŒå€¼)
                if np.mean(cropped**2) > 1e-5:
                    break
            else:
                # å¦‚æœ3æ¬¡éƒ½å¤±è´¥(æç½•è§)ï¼Œå…œåº•æ–¹æ¡ˆï¼šå–æ­£ä¸­é—´
                start = max_start // 2
                cropped = simulated_audio[:, start : start + self.sample_length]
                
        else:
            # è¡¥é›¶ (Padding)
            pad_width = self.sample_length - signal_len
            cropped = np.pad(simulated_audio, ((0,0), (0, pad_width)))

        # è½¬ Tensor
        audio_tensor = torch.from_numpy(cropped.astype(np.float32))
        
        # è¿”å›è§’åº¦ Label
        label_tensor = torch.tensor(label_deg, dtype=torch.long) 

        return audio_tensor, label_tensor